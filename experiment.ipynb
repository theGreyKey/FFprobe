{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3e96c3",
   "metadata": {},
   "source": [
    "### Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31329bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "# Custom module imports\n",
    "from config import DATA_LIMIT, get_feature_path, get_checkpoint_path, HIDDEN_DIM, MODEL_ID, CACHE_DIR\n",
    "from core import FFLayerProbe\n",
    "from train_probe import calculate_ff_auroc\n",
    "\n",
    "# Configuration\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "TARGET_LAYER = 25\n",
    "\n",
    "# Load all features ONCE to avoid repeated I/O\n",
    "print(\"ðŸ“¥ Loading features...\")\n",
    "sqa_feat_path = get_feature_path(\"simpleqa\")\n",
    "lqa_feat_path = get_feature_path(\"logiqa\")\n",
    "\n",
    "sqa_data = torch.load(sqa_feat_path, map_location=DEVICE, weights_only=True)\n",
    "sqa_pos = sqa_data[\"pos\"].to(DEVICE)\n",
    "sqa_neg = sqa_data[\"neg\"].to(DEVICE)\n",
    "\n",
    "lqa_data = torch.load(lqa_feat_path, map_location=DEVICE, weights_only=True)\n",
    "lqa_pos = lqa_data[\"pos\"].to(DEVICE)\n",
    "lqa_neg = lqa_data[\"neg\"].to(DEVICE)\n",
    "\n",
    "print(f\"âœ… SimpleQA Shape: {sqa_pos.shape}\")\n",
    "print(f\"âœ… LogiQA Shape: {lqa_pos.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸš€ Loading Model...\")\n",
    "model_dir = snapshot_download(\n",
    "    MODEL_ID, \n",
    "    cache_dir=CACHE_DIR, \n",
    "    revision='master',\n",
    "    ignore_patterns=[\"*.gguf\", \"*.pth\", \"*.pt\", \"original/*\"] \n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\", \n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n",
    "print(\"âœ… Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccd605",
   "metadata": {},
   "source": [
    "### Run All Models (Fast Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788433b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.baselines import calculate_prob_entropy_auroc\n",
    "from utils import prepare_simpleqa_data\n",
    "\n",
    "def get_generation_probabilities(model, tokenizer, dataset):\n",
    "    \"\"\"Calculates the mean log probability of the generated target for Probability Baseline.\"\"\"\n",
    "    pos_probs = []\n",
    "    neg_probs = []\n",
    "    \n",
    "    # Ensure pad token is set\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataset, desc=\"Calculating Probability Baseline\"):\n",
    "            # Compute for Positive Target\n",
    "            pos_text = f\"Question: {item['user_content']}\\nAnswer: {item['pos_target']}\"\n",
    "            pos_inputs = tokenizer(pos_text, return_tensors=\"pt\").to(model.device)\n",
    "            pos_outputs = model(**pos_inputs, labels=pos_inputs[\"input_ids\"], use_cache=False)\n",
    "            # Neg-log-likelihood is the loss, we convert it to probability score (-loss = log prob)\n",
    "            pos_probs.append(-pos_outputs.loss.item())\n",
    "            \n",
    "            # Compute for Negative Target\n",
    "            neg_text = f\"Question: {item['user_content']}\\nAnswer: {item['neg_target']}\"\n",
    "            neg_inputs = tokenizer(neg_text, return_tensors=\"pt\").to(model.device)\n",
    "            neg_outputs = model(**neg_inputs, labels=neg_inputs[\"input_ids\"], use_cache=False)\n",
    "            neg_probs.append(-neg_outputs.loss.item())\n",
    "            \n",
    "    return pos_probs, neg_probs\n",
    "\n",
    "print(\"ðŸš€ Extracting Probabilities for Entropy Baseline...\")\n",
    "simpleqa_data = prepare_simpleqa_data(model, tokenizer, limit=200)\n",
    "pos_probs, neg_probs = get_generation_probabilities(model, tokenizer, simpleqa_data)\n",
    "prob_baseline_auroc = calculate_prob_entropy_auroc(pos_probs, neg_probs)\n",
    "print(f\"âœ… Probability Baseline AUROC: {prob_baseline_auroc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from core import FFLayerProbe\n",
    "from utils import (\n",
    "    calculate_lr_auroc, calculate_mass_mean_auroc, \n",
    "    calculate_mlp_auroc, calculate_ccs_auroc,\n",
    "    plot_auroc_comparison, plot_snr_distribution,\n",
    "    generate_academic_baseline_table\n",
    ")\n",
    "from utils.advanced_baselines import (\n",
    "    calculate_knn_auroc, calculate_mahalanobis_auroc,\n",
    "    calculate_lda_auroc, calculate_repe_auroc,\n",
    "    calculate_nlccs_auroc, calculate_saplma_auroc,\n",
    "    calculate_concept_bottleneck_auroc,\n",
    ")\n",
    "from utils.evaluation import (\n",
    "    compute_full_metrics, bootstrap_auroc_ci,\n",
    "    mcnemar_test, delong_test,\n",
    "    compare_probes, print_evaluation_report,\n",
    "    get_method_scores_at_layer\n",
    ")\n",
    "\n",
    "# 1. Load FF Probe\n",
    "print(\"\\nðŸš€ Loading FF Probe + PeerNorm...\")\n",
    "metrics_path = get_checkpoint_path(\"metrics\")\n",
    "weights_path = get_checkpoint_path(\"weights\")\n",
    "metrics = torch.load(metrics_path)\n",
    "ff_weights = torch.load(weights_path)\n",
    "\n",
    "results_dict = {}\n",
    "results_dict['Ours (FF Probe + PeerNorm)'] = metrics['FF_SimpleQA_Mean']\n",
    "\n",
    "# 2. Basic Baselines\n",
    "print(\"\\nðŸš€ Calculating Basic Baselines...\")\n",
    "n_layers = sqa_pos.shape[1]\n",
    "results_dict['Baseline (Probability)'] = [prob_baseline_auroc] * n_layers\n",
    "results_dict['Baseline (CCS)'] = calculate_ccs_auroc(sqa_pos, sqa_neg, device=DEVICE)\n",
    "results_dict['Baseline (LR)'] = calculate_lr_auroc(sqa_pos, sqa_neg)\n",
    "results_dict['Baseline (Mass-Mean)'] = calculate_mass_mean_auroc(sqa_pos, sqa_neg)\n",
    "results_dict['Baseline (MLP)'] = calculate_mlp_auroc(sqa_pos, sqa_neg, n_epochs=50, device=DEVICE)\n",
    "\n",
    "# 3. Advanced Baselines\n",
    "print(\"\\nðŸš€ Calculating Advanced Baselines...\")\n",
    "results_dict['Baseline (KNN)'] = calculate_knn_auroc(sqa_pos, sqa_neg)\n",
    "results_dict['Baseline (Mahalanobis)'] = calculate_mahalanobis_auroc(sqa_pos, sqa_neg)\n",
    "results_dict['Baseline (LDA)'] = calculate_lda_auroc(sqa_pos, sqa_neg)\n",
    "results_dict['Baseline (RepE)'] = calculate_repe_auroc(sqa_pos, sqa_neg)\n",
    "results_dict['Baseline (NL-CCS)'] = calculate_nlccs_auroc(sqa_pos, sqa_neg, n_epochs=50, device=DEVICE)\n",
    "results_dict['Baseline (SAPLMA)'] = calculate_saplma_auroc(sqa_pos, sqa_neg, n_epochs=50, device=DEVICE)\n",
    "results_dict['Baseline (ConceptBottleneck)'] = calculate_concept_bottleneck_auroc(sqa_pos, sqa_neg, n_epochs=50, device=DEVICE)\n",
    "\n",
    "print(\"\\nâœ… All Baselines Evaluated!\")\n",
    "\n",
    "# 4. Visualization & Reporting\n",
    "plot_auroc_comparison(results_dict)\n",
    "benchmark_df = generate_academic_baseline_table(results_dict)\n",
    "\n",
    "# 5. Statistical Comparison at Best Layer\n",
    "TARGET_LAYER = 25\n",
    "print(f\"\\nðŸš€ Statistical Analysis at Layer {TARGET_LAYER}...\")\n",
    "\n",
    "best_model_info = ff_weights[TARGET_LAYER]\n",
    "probe = FFLayerProbe(in_dim=sqa_pos.shape[-1], hidden_dim=HIDDEN_DIM, device=DEVICE)\n",
    "probe.load_state_dict(best_model_info['state_dict'])\n",
    "probe.eval()\n",
    "\n",
    "split_idx = int(sqa_pos.shape[0] * 0.7)\n",
    "with torch.no_grad():\n",
    "    sp = probe(sqa_pos[split_idx:, TARGET_LAYER, :].to(DEVICE)).cpu().numpy()\n",
    "    sn = probe(sqa_neg[split_idx:, TARGET_LAYER, :].to(DEVICE)).cpu().numpy()\n",
    "\n",
    "plot_snr_distribution(sp, sn, layer_idx=TARGET_LAYER, learned_threshold=best_model_info['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './checkpoints/all_baselines_results.pt'\n",
    "torch.save(results_dict, save_path)\n",
    "print(f\"âœ… results_dict successfully saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import *\n",
    "load_path = './checkpoints/all_baselines_results.pt'\n",
    "results_dict = torch.load(load_path, weights_only=False)\n",
    "print(\"âœ… results_dict successfully loaded!\")\n",
    "\n",
    "split_idx = int(sqa_pos.shape[0] * 0.7)\n",
    "with torch.no_grad():\n",
    "    sp = probe(sqa_pos[split_idx:, TARGET_LAYER, :].to(DEVICE)).cpu().numpy()\n",
    "    sn = probe(sqa_neg[split_idx:, TARGET_LAYER, :].to(DEVICE)).cpu().numpy()\n",
    "\n",
    "\n",
    "# Prepare scores for statistical testing\n",
    "y_true_at_best = np.concatenate([np.ones(len(sp)), np.zeros(len(sn))])\n",
    "scores_at_best = {\n",
    "    'FF-Probe (Ours)': np.concatenate([sp, sn]),\n",
    "}\n",
    "\n",
    "for method_name in results_dict.keys():\n",
    "    if method_name != 'Ours (FF Probe + PeerNorm)' and method_name != 'Baseline (Probability)':\n",
    "        # DEVICE must be available in scope for MLP inner workings in evaluation\n",
    "        scores_at_best[method_name] = get_method_scores_at_layer(\n",
    "            method_name, sqa_pos, sqa_neg, TARGET_LAYER, split_idx\n",
    "        )\n",
    "\n",
    "results = compare_probes(\n",
    "    y_true_at_best,\n",
    "    scores_at_best,\n",
    "    reference_method='FF-Probe (Ours)',\n",
    "    n_bootstrap=2000,\n",
    ")\n",
    "\n",
    "print_evaluation_report(results, show_comparisons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils.baselines import calculate_ff_no_peernorm_auroc\n",
    "\n",
    "print(\"ðŸš€ Starting Ablation Study: PeerNorm Impact Across Layers...\")\n",
    "\n",
    "print(\"\\nTraining Ablation: Without PeerNorm...\")\n",
    "no_peernorm_aurocs = calculate_ff_no_peernorm_auroc(sqa_pos, sqa_neg, n_epochs=50, device=DEVICE)\n",
    "\n",
    "full_aurocs = results_dict['Ours (FF Probe + PeerNorm)']\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\", font_scale=0.9)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "layers = np.arange(len(full_aurocs))\n",
    "\n",
    "\n",
    "ax.plot(layers, full_aurocs, label='FFprobe (Full: w/ PeerNorm)', \n",
    "        color='#E74C3C', linewidth=3.0, linestyle='-', marker='o', markersize=7, alpha=0.9)\n",
    "\n",
    "ax.plot(layers, no_peernorm_aurocs, label='Ablation (w/o PeerNorm)', \n",
    "        color='#E67E22', linewidth=2.5, linestyle='--', marker='v', markersize=7, alpha=0.9)\n",
    "ax.axhline(0.5, color='black', linestyle=':', linewidth=1.5, label='Random Chance')\n",
    "ax.set_title(\"Ablation Study: Impact of PeerNorm on Layer-wise Stability\", fontsize=16, fontweight='bold', pad=15)\n",
    "ax.set_xlabel(\"Layer Depth\", fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel(\"AUROC Score\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Dynamic y-axis to fit data properly\n",
    "y_min = min(min(full_aurocs), min(no_peernorm_aurocs)) - 0.05\n",
    "ax.set_ylim(max(0.4, y_min), 1.05)\n",
    "ax.set_xlim(-1, len(layers))\n",
    "\n",
    "ax.legend(loc='lower right', frameon=True, fontsize=12, fancybox=True, shadow=True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fdc777",
   "metadata": {},
   "source": [
    "### Cognitive Orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b329b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_origin_tracing_experiment(sqa_pos, sqa_neg, lqa_pos, lqa_neg):\n",
    "    print(\"ðŸš€ Training Probe for SimpleQA (Facts)...\")\n",
    "    sqa_aucs, sqa_models = calculate_ff_auroc(sqa_pos, sqa_neg, n_epochs=50)\n",
    "    \n",
    "    print(\"ðŸš€ Training Probe for LogiQA (Logic)...\")\n",
    "    lqa_aucs, lqa_models = calculate_ff_auroc(lqa_pos, lqa_neg, n_epochs=50)\n",
    "    \n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    layers = list(range(len(sqa_aucs)))\n",
    "    plt.plot(layers, sqa_aucs, marker='o', color='#E74C3C', linewidth=2.5, markersize=8, label='SimpleQA (Factual Memory)')\n",
    "    plt.plot(layers, lqa_aucs, marker='^', color='#8E44AD', linewidth=2.5, markersize=8, label='LogiQA (Logical Routing)')\n",
    "    \n",
    "    plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7)\n",
    "    plt.title('Layer-wise Origin Tracing: Facts vs. Logic in Llama-3', fontsize=16, pad=15)\n",
    "    plt.xlabel('Transformer Layer Depth', fontsize=14)\n",
    "    plt.ylabel('FF Probe AUROC', fontsize=14)\n",
    "    plt.legend(loc='lower right', fontsize=12, frameon=True, shadow=True)\n",
    "    plt.ylim(0.4, 1.0)\n",
    "    plt.xticks(range(0, len(layers), 2))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return sqa_models, lqa_models\n",
    "\n",
    "sqa_models, lqa_models = run_origin_tracing_experiment(sqa_pos, sqa_neg, lqa_pos, lqa_neg)\n",
    "print(\"âœ… Models successfully saved to `sqa_models` and `lqa_models`!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fda30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_landscape(probe, sqa_pos, sqa_neg, lqa_pos, lqa_neg, target_layer):\n",
    "    probe.eval()\n",
    "    with torch.no_grad():\n",
    "        g_sqa_pos = probe(sqa_pos[:, target_layer, :]).cpu().numpy()\n",
    "        g_sqa_neg = probe(sqa_neg[:, target_layer, :]).cpu().numpy()\n",
    "        g_lqa_pos = probe(lqa_pos[:, target_layer, :]).cpu().numpy()\n",
    "        g_lqa_neg = probe(lqa_neg[:, target_layer, :]).cpu().numpy()\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    sns.kdeplot(g_sqa_pos, fill=True, color='#2ECC71', alpha=0.5, linewidth=2, label='True Fact (Pos)', ax=axes[0])\n",
    "    sns.kdeplot(g_sqa_neg, fill=True, color='#E74C3C', alpha=0.5, linewidth=2, label='Hallucination (Neg)', ax=axes[0])\n",
    "    axes[0].set_title(f'Source Domain (SimpleQA) - Layer {target_layer}')\n",
    "    axes[0].legend(loc='upper right', frameon=True)\n",
    "\n",
    "    sns.kdeplot(g_lqa_pos, fill=True, color='#2ECC71', alpha=0.5, linewidth=2, label='Correct Logic (Pos)', ax=axes[1])\n",
    "    sns.kdeplot(g_lqa_neg, fill=True, color='#E74C3C', alpha=0.5, linewidth=2, label='Logical Error (Neg)', ax=axes[1])\n",
    "    axes[1].set_title(f'Target Domain (LogiQA) - Layer {target_layer}')\n",
    "    axes[1].legend(loc='upper right', frameon=True)\n",
    "\n",
    "    plt.suptitle('Cross-Domain Goodness Landscape: Feature Reversal Phenomenon', fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_independent_logiqa_landscape(lqa_pos, lqa_neg, target_layer):\n",
    "    print(f\"ðŸš€ Training Dedicated Logic Probe for Layer {target_layer}...\")\n",
    "    logic_probe = FFLayerProbe(in_dim=lqa_pos.shape[2]).to(DEVICE)\n",
    "    \n",
    "    Xp, Xn = lqa_pos[:, target_layer, :], lqa_neg[:, target_layer, :]\n",
    "    for _ in range(150):\n",
    "        logic_probe.train_step(Xp, Xn)\n",
    "        \n",
    "    logic_probe.eval()\n",
    "    with torch.no_grad():\n",
    "        g_lqa_pos = logic_probe(Xp).cpu().numpy()\n",
    "        g_lqa_neg = logic_probe(Xn).cpu().numpy()\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.kdeplot(g_lqa_pos, fill=True, color='#2ECC71', alpha=0.6, linewidth=2, label='Correct Logic (Pos)')\n",
    "    sns.kdeplot(g_lqa_neg, fill=True, color='#E74C3C', alpha=0.6, linewidth=2, label='Logical Error (Neg)')\n",
    "    \n",
    "    plt.title(f'Target Domain (LogiQA) - Dedicated Probe at Layer {target_layer}', fontsize=15, pad=15)\n",
    "    plt.legend(loc='upper right', frameon=True, shadow=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Extract the probe trained purely on SimpleQA from earlier\n",
    "best_model_info = ff_weights[TARGET_LAYER]\n",
    "input_dim = sqa_pos.shape[-1]\n",
    "sqa_probe = FFLayerProbe(in_dim=input_dim, hidden_dim=HIDDEN_DIM, device=DEVICE).to(DEVICE)\n",
    "sqa_probe.load_state_dict(best_model_info['state_dict'])\n",
    "sqa_probe.eval()\n",
    "\n",
    "plot_energy_landscape(sqa_probe, sqa_pos, sqa_neg, lqa_pos, lqa_neg, TARGET_LAYER)\n",
    "plot_independent_logiqa_landscape(lqa_pos, lqa_neg, TARGET_LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_neuron_attribution(sqa_probe, lqa_probe, top_k=50):\n",
    "    print(\"ðŸš€ Analyzing Probe Weights for Dimensional Orthogonality...\")\n",
    "    \n",
    "    # FIX: Average the absolute weights across the hidden dimension (dim=0) \n",
    "    # to get a 1D importance score for each input neuron.\n",
    "    sqa_weights = sqa_probe.linear.weight.detach().cpu().abs().mean(dim=0)\n",
    "    lqa_weights = lqa_probe.linear.weight.detach().cpu().abs().mean(dim=0)\n",
    "    \n",
    "    # Now these are 1D tensors\n",
    "    sqa_top_indices = torch.argsort(sqa_weights, descending=True)[:top_k]\n",
    "    lqa_top_indices = torch.argsort(lqa_weights, descending=True)[:top_k]\n",
    "    \n",
    "    # FIX: Convert 1D tensors to standard Python lists before turning into sets\n",
    "    sqa_set = set(sqa_top_indices.tolist())\n",
    "    lqa_set = set(lqa_top_indices.tolist())\n",
    "    \n",
    "    overlap_ratio = len(sqa_set.intersection(lqa_set)) / top_k\n",
    "    print(f\"ðŸ“Š Top-{top_k} Neuron Overlap between Facts and Logic: {overlap_ratio*100:.1f}%\")\n",
    "    \n",
    "    # Visualization data\n",
    "    sqa_vals_in_sqa = sqa_weights[sqa_top_indices].numpy()\n",
    "    sqa_vals_in_lqa = lqa_weights[sqa_top_indices].numpy()\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    x = np.arange(top_k)\n",
    "    width = 0.4\n",
    "    \n",
    "    plt.bar(x - width/2, sqa_vals_in_sqa, width, label='Importance in Fact Probe', color='#E74C3C')\n",
    "    plt.bar(x + width/2, sqa_vals_in_lqa, width, label='Importance in Logic Probe', color='#8E44AD', alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Cognitive Orthogonality: Top {top_k} Factual Neurons are Ignored by Logic Probe', fontsize=16, pad=15)\n",
    "    plt.xlabel('Top Factual Neuron Indices (Sorted by Importance)', fontsize=14)\n",
    "    plt.ylabel('Mean Absolute Weight Magnitude', fontsize=14)\n",
    "    plt.legend(loc='upper right', frameon=True, shadow=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Setup probes using explicitly saved models ---\n",
    "TARGET_LAYER = 25\n",
    "input_dim = sqa_pos.shape[2]\n",
    "\n",
    "sqa_probe = FFLayerProbe(in_dim=input_dim, hidden_dim=HIDDEN_DIM, device=DEVICE).to(DEVICE)\n",
    "sqa_probe.load_state_dict(sqa_models[TARGET_LAYER]['state_dict'])\n",
    "\n",
    "lqa_probe = FFLayerProbe(in_dim=input_dim, hidden_dim=HIDDEN_DIM, device=DEVICE).to(DEVICE)\n",
    "lqa_probe.load_state_dict(lqa_models[TARGET_LAYER]['state_dict'])\n",
    "\n",
    "plot_neuron_attribution(sqa_probe, lqa_probe, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_topk_overlap_sweep(sqa_probe, lqa_probe, hidden_dim, k_list):\n",
    "    print(\"ðŸš€ Running Top-K Sweep for Neuron Overlap...\")\n",
    "    \n",
    "    # 1. Extract 1D importance scores\n",
    "    sqa_weights = sqa_probe.linear.weight.detach().cpu().abs().mean(dim=0)\n",
    "    lqa_weights = lqa_probe.linear.weight.detach().cpu().abs().mean(dim=0)\n",
    "    \n",
    "    overlap_ratios = []\n",
    "    random_chances = []\n",
    "    \n",
    "    # 2. Sweep across different K values\n",
    "    for k in k_list:\n",
    "        sqa_top_indices = set(torch.argsort(sqa_weights, descending=True)[:k].tolist())\n",
    "        lqa_top_indices = set(torch.argsort(lqa_weights, descending=True)[:k].tolist())\n",
    "        \n",
    "        # Calculate empirical overlap\n",
    "        overlap = len(sqa_top_indices.intersection(lqa_top_indices)) / k\n",
    "        overlap_ratios.append(overlap)\n",
    "        \n",
    "        # Calculate theoretical random chance overlap: K / Total_Dimension\n",
    "        random_chance = k / hidden_dim\n",
    "        random_chances.append(random_chance)\n",
    "        \n",
    "        print(f\"   K={k:<4} | Actual Overlap: {overlap*100:>5.2f}% | Expected Random: {random_chance*100:>5.2f}%\")\n",
    "        \n",
    "    # 3. Visualization\n",
    "    sns.set_theme(style=\"whitegrid\", context=\"talk\", font_scale=0.9)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.plot(k_list, overlap_ratios, marker='o', color='#8E44AD', linewidth=3, markersize=8, label='Empirical Neuron Overlap')\n",
    "    plt.plot(k_list, random_chances, linestyle='--', color='gray', linewidth=2, label='Theoretical Random Chance')\n",
    "    \n",
    "    plt.title('Cognitive Separation: Neuron Overlap Across Top-K Sweep', fontsize=16, fontweight='bold', pad=15)\n",
    "    plt.xlabel('Top-K Neurons Selected', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Overlap Ratio', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Dynamic y-axis scaling\n",
    "    max_y = max(max(overlap_ratios), max(random_chances)) + 0.05\n",
    "    plt.ylim(-0.01, max(0.2, max_y)) \n",
    "    \n",
    "    plt.legend(loc='upper left', frameon=True, shadow=True, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Execution ===\n",
    "# Make sure sqa_probe and lqa_probe are already loaded from your previous cell\n",
    "TARGET_LAYER = 25\n",
    "HIDDEN_DIM = sqa_pos.shape[2]  # typically 4096 for Llama-3.1-8B\n",
    "\n",
    "sweep_ks = [10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "plot_topk_overlap_sweep(sqa_probe, lqa_probe, hidden_dim=HIDDEN_DIM, k_list=sweep_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533224b7",
   "metadata": {},
   "source": [
    "### Surgical Continual Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f90709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from utils import( \n",
    "    FFLayerProbeNoZScore,\n",
    "    FFLayerProbeNoPeerNorm,\n",
    "    StandardMLP\n",
    ")\n",
    "\n",
    "def compute_auc_generic(model, pos_feat, neg_feat, is_mlp=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if is_mlp:\n",
    "            p = model(pos_feat).cpu().numpy()\n",
    "            n = model(neg_feat).cpu().numpy()\n",
    "        else:\n",
    "            p = model(pos_feat).cpu().numpy()\n",
    "            n = model(neg_feat).cpu().numpy()\n",
    "            \n",
    "    y_true = [1] * len(p) + [0] * len(n)\n",
    "    return roc_auc_score(y_true, list(p) + list(n))\n",
    "\n",
    "def run_robust_continual_learning(sqa_pos, sqa_neg, lqa_pos, lqa_neg, target_layer=30, n_seeds=3):\n",
    "    print(f\"ðŸš€ Running Continual Learning across {n_seeds} seeds at Layer {target_layer}...\")\n",
    "    input_dim = sqa_pos.shape[-1]\n",
    "    device = sqa_pos.device\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for seed in range(n_seeds):\n",
    "        print(f\"\\n--- Seed {seed + 1}/{n_seeds} ---\")\n",
    "        torch.manual_seed(42 + seed)\n",
    "        np.random.seed(42 + seed)\n",
    "        \n",
    "        # 1. Data Shuffling & Splitting\n",
    "        sqa_idx = torch.randperm(sqa_pos.shape[0])\n",
    "        lqa_idx = torch.randperm(lqa_pos.shape[0])\n",
    "        \n",
    "        sqa_p = sqa_pos[sqa_idx, target_layer, :]\n",
    "        sqa_n = sqa_neg[sqa_idx, target_layer, :]\n",
    "        lqa_p = lqa_pos[lqa_idx, target_layer, :]\n",
    "        lqa_n = lqa_neg[lqa_idx, target_layer, :]\n",
    "        \n",
    "        split_idx = int(sqa_p.shape[0] * 0.7)\n",
    "        sqa_p_tr, sqa_p_te = sqa_p[:split_idx], sqa_p[split_idx:]\n",
    "        sqa_n_tr, sqa_n_te = sqa_n[:split_idx], sqa_n[split_idx:]\n",
    "        \n",
    "        # Setup specific for the surgical fine-tuning (e.g., 150 target domain, 30 replay)\n",
    "        few_shot_size, replay_size = 150, 30\n",
    "        lqa_p_few, lqa_p_te = lqa_p[:few_shot_size], lqa_p[few_shot_size:]\n",
    "        lqa_n_few, lqa_n_te = lqa_n[:few_shot_size], lqa_n[few_shot_size:]\n",
    "        \n",
    "        sqa_p_rep, sqa_n_rep = sqa_p[:replay_size], sqa_n[:replay_size]\n",
    "        \n",
    "        # Mixed Batch for MLP Baseline\n",
    "        mixed_X = torch.cat([lqa_p_few, sqa_p_rep, lqa_n_few, sqa_n_rep], dim=0)\n",
    "        mixed_y = torch.cat([\n",
    "            torch.ones(len(lqa_p_few), device=device), \n",
    "            torch.ones(len(sqa_p_rep), device=device),\n",
    "            torch.zeros(len(lqa_n_few), device=device), \n",
    "            torch.zeros(len(sqa_n_rep), device=device)\n",
    "        ])\n",
    "        \n",
    "        sqa_X_tr = torch.cat([sqa_p_tr, sqa_n_tr], dim=0)\n",
    "        sqa_y_tr = torch.cat([torch.ones(len(sqa_p_tr), device=device), torch.zeros(len(sqa_n_tr), device=device)])\n",
    "\n",
    "        # 2. Initialize Models\n",
    "        ff_full = FFLayerProbe(in_dim=input_dim, hidden_dim=256, device=device).to(device)\n",
    "        ff_no_z = FFLayerProbeNoZScore(in_dim=input_dim, hidden_dim=256, device=device).to(device)\n",
    "        ff_no_p = FFLayerProbeNoPeerNorm(in_dim=input_dim, hidden_dim=256, device=device).to(device)\n",
    "        mlp_model = StandardMLP(in_dim=input_dim, hidden_dim=256).to(device)\n",
    "        \n",
    "        mlp_opt = optim.Adam(mlp_model.parameters(), lr=0.005, weight_decay=1e-3)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        # 3. Pre-Calibration (Train heavily on Facts)\n",
    "        for _ in range(150):\n",
    "            ff_full.train_step(sqa_p_tr, sqa_n_tr)\n",
    "            ff_no_z.train_step(sqa_p_tr, sqa_n_tr)\n",
    "            ff_no_p.train_step(sqa_p_tr, sqa_n_tr)\n",
    "            \n",
    "            mlp_model.train()\n",
    "            mlp_opt.zero_grad()\n",
    "            loss = criterion(mlp_model(sqa_X_tr), sqa_y_tr)\n",
    "            loss.backward()\n",
    "            mlp_opt.step()\n",
    "            \n",
    "        models_dict = {\n",
    "            \"FFprobe (Full)\": (ff_full, False),\n",
    "            \"FFprobe (No Z-Score)\": (ff_no_z, False),\n",
    "            \"FFprobe (No PeerNorm)\": (ff_no_p, False),\n",
    "            \"MLP Baseline\": (mlp_model, True)\n",
    "        }\n",
    "        \n",
    "        pre_aucs = {}\n",
    "        for name, (m, is_mlp) in models_dict.items():\n",
    "            pre_aucs[name] = {\n",
    "                \"Facts\": compute_auc_generic(m, sqa_p_te, sqa_n_te, is_mlp),\n",
    "                \"Logic\": compute_auc_generic(m, lqa_p_te, lqa_n_te, is_mlp)\n",
    "            }\n",
    "            \n",
    "        # 4. Surgical Fine-Tuning Setup\n",
    "        ff_full.optimizer = optim.AdamW(ff_full.parameters(), lr=0.0005, weight_decay=0.05)\n",
    "        ff_no_z.optimizer = optim.AdamW(ff_no_z.parameters(), lr=0.0005, weight_decay=0.05)\n",
    "        ff_no_p.optimizer = optim.AdamW(ff_no_p.parameters(), lr=0.0005, weight_decay=0.05)\n",
    "        for param_group in mlp_opt.param_groups: \n",
    "            param_group['lr'] = 0.001\n",
    "            param_group['weight_decay'] = 0.05\n",
    "\n",
    "        # 5. Continual Learning Process\n",
    "        SURGICAL_EPOCHS = 50\n",
    "        for _ in range(SURGICAL_EPOCHS):\n",
    "            # Alternating Domain Replay for FF models\n",
    "            for m_ff in [ff_full, ff_no_z, ff_no_p]:\n",
    "                m_ff.train_step(lqa_p_few, lqa_n_few)\n",
    "                m_ff.train_step(sqa_p_rep, sqa_n_rep)\n",
    "                \n",
    "            # Standard Batch BP for MLP\n",
    "            mlp_model.train()\n",
    "            mlp_opt.zero_grad()\n",
    "            loss = criterion(mlp_model(mixed_X), mixed_y)\n",
    "            loss.backward()\n",
    "            mlp_opt.step()\n",
    "            \n",
    "        # 6. Post-Calibration Evaluation\n",
    "        for name, (m, is_mlp) in models_dict.items():\n",
    "            post_sqa = compute_auc_generic(m, sqa_p_te, sqa_n_te, is_mlp)\n",
    "            post_lqa = compute_auc_generic(m, lqa_p_te, lqa_n_te, is_mlp)\n",
    "            \n",
    "            results.append({\"Seed\": seed, \"Model\": name, \"Task\": \"Source (Facts)\",\n",
    "                            \"Pre-AUC\": pre_aucs[name][\"Facts\"], \"Post-AUC\": post_sqa, \n",
    "                            \"Delta\": post_sqa - pre_aucs[name][\"Facts\"]})\n",
    "            results.append({\"Seed\": seed, \"Model\": name, \"Task\": \"Target (Logic)\",\n",
    "                            \"Pre-AUC\": pre_aucs[name][\"Logic\"], \"Post-AUC\": post_lqa, \n",
    "                            \"Delta\": post_lqa - pre_aucs[name][\"Logic\"]})\n",
    "\n",
    "    # 7. Aggregate Results across Seeds\n",
    "    df = pd.DataFrame(results)\n",
    "    agg_df = df.groupby([\"Model\", \"Task\"]).agg({\n",
    "        \"Pre-AUC\": [\"mean\", \"std\"], \"Post-AUC\": [\"mean\", \"std\"], \"Delta\": [\"mean\", \"std\"]\n",
    "    }).reset_index()\n",
    "    \n",
    "    formatted_data = []\n",
    "    for _, row in agg_df.iterrows():\n",
    "        model, task = row[(\"Model\", \"\")], row[(\"Task\", \"\")]\n",
    "        pre_m, pre_s = row[(\"Pre-AUC\", \"mean\")], row[(\"Pre-AUC\", \"std\")]\n",
    "        post_m, post_s = row[(\"Post-AUC\", \"mean\")], row[(\"Post-AUC\", \"std\")]\n",
    "        delta_m, delta_s = row[(\"Delta\", \"mean\")], row[(\"Delta\", \"std\")]\n",
    "        \n",
    "        formatted_data.append({\n",
    "            \"Model\": model, \"Task\": task,\n",
    "            \"Pre-AUC\": f\"{pre_m:.4f} Â± {pre_s:.4f}\",\n",
    "            \"Post-AUC\": f\"{post_m:.4f} Â± {post_s:.4f}\",\n",
    "            \"Delta (BWT/FWT)\": f\"{delta_m:+.4f} Â± {delta_s:.4f}\"\n",
    "        })\n",
    "        \n",
    "    final_df = pd.DataFrame(formatted_data)\n",
    "    \n",
    "    # Sort for cleaner table presentation\n",
    "    model_order = {\"FFprobe (Full)\": 0, \"FFprobe (No Z-Score)\": 1, \"FFprobe (No PeerNorm)\": 2, \"MLP Baseline\": 3}\n",
    "    final_df[\"Order\"] = final_df[\"Model\"].map(model_order)\n",
    "    final_df = final_df.sort_values([\"Order\", \"Task\"]).drop(columns=[\"Order\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*85)\n",
    "    print(f\"ðŸ“Š Robust Continual Learning Matrix (Averaged over {n_seeds} Seeds)\")\n",
    "    print(\"=\"*85)\n",
    "    print(final_df.to_string(index=False))\n",
    "    print(\"=\"*85 + \"\\n\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Execution (Make sure lqa_pos, lqa_neg, sqa_pos, sqa_neg are in memory)\n",
    "final_cl_df = run_robust_continual_learning(sqa_pos, sqa_neg, lqa_pos, lqa_neg, target_layer=30, n_seeds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fb9e3",
   "metadata": {},
   "source": [
    "### Energy Landscape & Phase Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387280b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_activation_interpolation(probe, pos_feat, neg_feat, target_layer, num_steps=100):\n",
    "    probe.eval()\n",
    "    alphas = np.linspace(0, 1, num_steps)\n",
    "    \n",
    "    p_feat = pos_feat[:, target_layer, :]\n",
    "    n_feat = neg_feat[:, target_layer, :]\n",
    "    min_len = min(p_feat.shape[0], n_feat.shape[0])\n",
    "    p_feat = p_feat[:min_len]\n",
    "    n_feat = n_feat[:min_len]\n",
    "    \n",
    "    mean_scores = []\n",
    "    std_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for alpha in alphas:\n",
    "            h_alpha = (1 - alpha) * p_feat + alpha * n_feat\n",
    "            g_scores = probe(h_alpha).cpu().numpy()\n",
    "            mean_scores.append(g_scores.mean())\n",
    "            std_scores.append(g_scores.std())\n",
    "            \n",
    "    mean_scores = np.array(mean_scores)\n",
    "    std_scores = np.array(std_scores)\n",
    "    \n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.plot(alphas, mean_scores, color='#2C3E50', linewidth=2.5, label='Mean Goodness')\n",
    "    plt.fill_between(alphas, \n",
    "                     mean_scores - std_scores * 0.1, \n",
    "                     mean_scores + std_scores * 0.1, \n",
    "                     color='#3498DB', alpha=0.2, label='Variance')\n",
    "    \n",
    "    plt.axvline(x=0.5, color='#E74C3C', linestyle='--', linewidth=1.5, alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Interpolation Alpha (0.0=Fact, 1.0=Hallucination)', fontsize=12)\n",
    "    plt.ylabel('FF Goodness Score', fontsize=12)\n",
    "    plt.title(f'Phase Transition in Representation Space (Layer {target_layer})', fontsize=14)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Execution assuming sqa_probe, sqa_pos, sqa_neg and TARGET_LAYER are in context\n",
    "TARGET_LAYER=30\n",
    "plot_activation_interpolation(sqa_probe, sqa_pos, sqa_neg, TARGET_LAYER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f981f5",
   "metadata": {},
   "source": [
    "### Causal Discovery via Goodness Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca06a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_goodness_attribution_and_ablation(probe, neg_feat, target_layer, top_k=30):\n",
    "    probe.eval()\n",
    "    \n",
    "    X_neg = neg_feat[:, target_layer, :].clone().detach().requires_grad_(True)\n",
    "    \n",
    "    g_scores = probe(X_neg)\n",
    "    loss = g_scores.mean()\n",
    "    loss.backward()\n",
    "    \n",
    "    feature_grads = X_neg.grad.abs().mean(dim=0)\n",
    "    top_indices = torch.argsort(feature_grads, descending=True)[:top_k]\n",
    "    \n",
    "    g_original = g_scores.detach().cpu().numpy()\n",
    "    \n",
    "    X_ablated = neg_feat[:, target_layer, :].clone().detach()\n",
    "    X_ablated[:, top_indices] = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        g_ablated = probe(X_ablated).cpu().numpy()\n",
    "        \n",
    "    rand_indices = torch.randperm(X_neg.shape[1])[:top_k]\n",
    "    X_rand = neg_feat[:, target_layer, :].clone().detach()\n",
    "    X_rand[:, rand_indices] = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        g_rand = probe(X_rand).cpu().numpy()\n",
    "        \n",
    "    labels = ['Original\\n(Hallucination)', f'Top-{top_k} Ablated\\n(Targeted)', f'Random-{top_k} Ablated\\n(Control)']\n",
    "    means = [g_original.mean(), g_ablated.mean(), g_rand.mean()]\n",
    "    stds = [g_original.std(), g_ablated.std(), g_rand.std()]\n",
    "    \n",
    "    plt.figure(figsize=(9, 6))\n",
    "    bars = plt.bar(labels, means, yerr=stds, capsize=10, \n",
    "                   color=['#E74C3C', '#2ECC71', '#95A5A6'], alpha=0.85, edgecolor='black')\n",
    "    \n",
    "    plt.ylabel('FF Goodness Score', fontsize=12)\n",
    "    plt.title(f'Causal Ablation via Goodness Gradient (Layer {target_layer})', fontsize=14)\n",
    "    \n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.02, f'{yval:.3f}', ha='center', va='bottom', fontsize=11)\n",
    "        \n",
    "    plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return top_indices\n",
    "\n",
    "# Execution\n",
    "TARGET_LAYER = 25\n",
    "top_neurons = run_goodness_attribution_and_ablation(sqa_probe, sqa_neg, TARGET_LAYER, top_k=30)\n",
    "print(f\"Top 30 causal neurons identified: {top_neurons.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304ba108",
   "metadata": {},
   "source": [
    "### Real-time Hallucination Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def format_prompt(text, tokenizer):\n",
    "    messages = [{\"role\": \"user\", \"content\": text}]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "def plot_goodness_trajectory(\n",
    "    prompt, model, tokenizer, probe, target_layer, \n",
    "    max_new_tokens=60, temperature=1.0\n",
    "):\n",
    "    print(f\"ðŸš€ Generating and Tracing Goodness for:\\n{prompt}\\n\")\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs.input_ids\n",
    "    \n",
    "    probe.eval()\n",
    "    \n",
    "    generated_tokens = []\n",
    "    g_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step in range(max_new_tokens):\n",
    "            outputs = model(input_ids, output_hidden_states=True, return_dict=True, use_cache=False)\n",
    "            \n",
    "            # Extract hidden state and align dtype\n",
    "            hidden_state = outputs.hidden_states[target_layer][:, -1, :]\n",
    "            hidden_state = hidden_state.to(probe.linear.weight.dtype)\n",
    "            \n",
    "            # Compute Goodness\n",
    "            g_score = probe(hidden_state).item()\n",
    "            g_scores.append(g_score)\n",
    "            \n",
    "            # Sample next token\n",
    "            logits = outputs.logits[:, -1, :] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            word = tokenizer.decode(next_token[0])\n",
    "            generated_tokens.append(word)\n",
    "            print(word, end=\"\", flush=True)\n",
    "            \n",
    "            input_ids = torch.cat([input_ids, next_token], dim=-1)\n",
    "            \n",
    "            if next_token.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "                \n",
    "    print(\"\\n\\nðŸ“Š Plotting Trajectory...\")\n",
    "    \n",
    "    # Plotting the trajectory\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    x_pos = np.arange(len(generated_tokens))\n",
    "    \n",
    "    # Color gradient based on goodness score (red for low/hallucination, green for high/fact)\n",
    "    norm = plt.Normalize(min(g_scores), max(g_scores))\n",
    "    colors = plt.cm.RdYlGn(norm(g_scores))\n",
    "    \n",
    "    plt.plot(x_pos, g_scores, color='gray', linestyle='-', alpha=0.5, zorder=1)\n",
    "    plt.scatter(x_pos, g_scores, c=colors, s=100, edgecolor='black', zorder=2)\n",
    "    \n",
    "    # Annotate tokens on the x-axis\n",
    "    plt.xticks(x_pos, [t.replace('\\n', '\\\\n') for t in generated_tokens], rotation=60, ha='right', fontsize=9)\n",
    "    \n",
    "    plt.title(f'Real-time Hallucination Trajectory (Layer {target_layer})', fontsize=16, pad=15)\n",
    "    plt.ylabel('FF Goodness Score', fontsize=14)\n",
    "    plt.xlabel('Generated Tokens', fontsize=14)\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return generated_tokens, g_scores\n",
    "\n",
    "# Trap: Fitzgerald didn't write it (GarcÃ­a MÃ¡rquez did), quote is from Dickens, and applies it to the BuendÃ­a family.\n",
    "prompt_quotes = \"In F. Scott Fitzgerald's masterpiece 'One Hundred Years of Solitude', he famously wrote: 'It was the best of times, it was the worst of times.' Discuss how this opening line deeply foreshadows the tragic decline of the BuendÃ­a family.\"\n",
    "\n",
    "# Trap: Hareton is Hindley's son, not Heathcliff's. Heathcliff's son is Linton Heathcliff. Isabella is Heathcliff's wife, not Hareton's lover (Hareton marries young Cathy).\n",
    "prompt_wuthering = \"Analyze the profound psychological impact on Heathcliff when he discovers that his biological son, Hareton Earnshaw, has fallen in love with and secretly married Isabella Linton.\"\n",
    "\n",
    "# Trap: Curie died in 1934 (not 1945). DNA double helix was 1953 (Watson/Crick/Franklin).\n",
    "prompt_science = \"Provide a detailed historical account of how Marie Curie's secret collaboration with Albert Einstein in 1945 directly led to the groundbreaking discovery of the DNA double helix structure.\"\n",
    "\n",
    "# === Execution ===\n",
    "TARGET_LAYER = 25\n",
    "weights_path = get_checkpoint_path(\"weights\")\n",
    "saved_weights = torch.load(weights_path, map_location=DEVICE)\n",
    "\n",
    "sqa_probe = FFLayerProbe(in_dim=sqa_pos.shape[2], hidden_dim=HIDDEN_DIM, device=DEVICE).to(DEVICE)\n",
    "sqa_probe.load_state_dict(saved_weights[TARGET_LAYER]['state_dict']) \n",
    "sqa_probe.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prompt 1: Wuthering Heights\n",
    "formatted_prompt_wuthering = format_prompt(prompt_wuthering, tokenizer)\n",
    "tokens_w, scores_w = plot_goodness_trajectory(\n",
    "    formatted_prompt_wuthering, model, tokenizer, sqa_probe, \n",
    "    TARGET_LAYER, max_new_tokens=80, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prompt 2: Literature Misattribution\n",
    "formatted_prompt_quotes = format_prompt(prompt_quotes, tokenizer)\n",
    "tokens_q, scores_q = plot_goodness_trajectory(\n",
    "    formatted_prompt_quotes, model, tokenizer, sqa_probe, \n",
    "    TARGET_LAYER, max_new_tokens=80, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prompt 3: Science\n",
    "formatted_prompt_quotes = format_prompt(prompt_science, tokenizer)\n",
    "tokens_q, scores_q = plot_goodness_trajectory(\n",
    "    formatted_prompt_quotes, model, tokenizer, sqa_probe, \n",
    "    TARGET_LAYER, max_new_tokens=80, temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa9c29",
   "metadata": {},
   "source": [
    "### Taxonomy & Asymmetric Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b231bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 1. Feature Extraction Functions (Your Code)\n",
    "from extract_features import build_universal_eval_prompt, build_cot_prompt, extract_hidden_states\n",
    "from utils import prepare_simpleqa_data\n",
    "\n",
    "# 2. Taxonomy Data Generation\n",
    "def generate_negative_taxonomy(clean_simpleqa_data):\n",
    "    taxonomy_data = {\n",
    "        \"N1_Natural\": [],\n",
    "        \"N2_EntitySwap\": [],\n",
    "        \"N3_Noise\": []\n",
    "    }\n",
    "    \n",
    "    plausible_swaps = [\"Newton\", \"Paris\", \"1998\", \"Google\", \"Jupiter\", \"Beethoven\", \"Water\", \"Oxygen\", \"Einstein\", \"London\"]\n",
    "    noise_tokens = [\"xyz123\", \"###\", \"null_ptr\", \"qwerty\", \"!!!\", \"unk_token\"]\n",
    "    \n",
    "    for item in clean_simpleqa_data:\n",
    "        item_n1 = copy.deepcopy(item)\n",
    "        taxonomy_data[\"N1_Natural\"].append(item_n1)\n",
    "        \n",
    "        item_n2 = copy.deepcopy(item)\n",
    "        swap = random.choice([s for s in plausible_swaps if s not in item['pos_target']])\n",
    "        item_n2['neg_target'] = swap\n",
    "        taxonomy_data[\"N2_EntitySwap\"].append(item_n2)\n",
    "        \n",
    "        item_n3 = copy.deepcopy(item)\n",
    "        item_n3['neg_target'] = random.choice(noise_tokens)\n",
    "        taxonomy_data[\"N3_Noise\"].append(item_n3)\n",
    "        \n",
    "    return taxonomy_data\n",
    "\n",
    "# 3. Main Execution & Matrix Plotting\n",
    "def run_taxonomy_cross_validation(model, tokenizer, source_data, target_layer=30):\n",
    "    print(\"ðŸš€ Starting Negative Taxonomy Generalization Test...\")\n",
    "    \n",
    "    # Generate 3 variations of the dataset\n",
    "    tax_datasets = generate_negative_taxonomy(source_data)\n",
    "    features_dict = {}\n",
    "    \n",
    "    # Extract features for all 3 variations\n",
    "    for tax_name, dataset in tax_datasets.items():\n",
    "        p_feat, n_feat = extract_hidden_states(model, tokenizer, dataset, dataset_type=f\"SimpleQA_{tax_name}\")\n",
    "        features_dict[tax_name] = {\"pos\": p_feat, \"neg\": n_feat}\n",
    "        \n",
    "    taxonomy_names = [\"N1_Natural\", \"N2_EntitySwap\", \"N3_Noise\"]\n",
    "    matrix_results = np.zeros((3, 3))\n",
    "    \n",
    "    input_dim = features_dict[\"N1_Natural\"][\"pos\"].shape[-1]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Training and Cross-Evaluating Probes at Layer {target_layer}...\")\n",
    "    \n",
    "    for i, train_name in enumerate(taxonomy_names):\n",
    "        train_pos = features_dict[train_name][\"pos\"][:, target_layer, :].to(DEVICE)\n",
    "        train_neg = features_dict[train_name][\"neg\"][:, target_layer, :].to(DEVICE)\n",
    "        \n",
    "        probe = FFLayerProbe(in_dim=input_dim, hidden_dim=256, device=DEVICE).to(DEVICE)\n",
    "        \n",
    "        for _ in range(50):\n",
    "            probe.train_step(train_pos, train_neg)\n",
    "            \n",
    "        probe.eval()\n",
    "        \n",
    "        for j, test_name in enumerate(taxonomy_names):\n",
    "            test_pos = features_dict[test_name][\"pos\"][:, target_layer, :].to(DEVICE)\n",
    "            test_neg = features_dict[test_name][\"neg\"][:, target_layer, :].to(DEVICE)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                g_pos = probe(test_pos).cpu().numpy()\n",
    "                g_neg = probe(test_neg).cpu().numpy()\n",
    "                \n",
    "            y_true = np.concatenate([np.ones(len(g_pos)), np.zeros(len(g_neg))])\n",
    "            y_scores = np.concatenate([g_pos, g_neg])\n",
    "            auc = roc_auc_score(y_true, y_scores)\n",
    "            \n",
    "            matrix_results[i, j] = auc\n",
    "            \n",
    "    # Plotting the Heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(matrix_results, annot=True, fmt=\".3f\", cmap=\"YlGnBu\", vmin=0.5, vmax=1.0,\n",
    "                xticklabels=[\"Test: Natural\", \"Test: EntitySwap\", \"Test: Noise\"],\n",
    "                yticklabels=[\"Train: Natural\", \"Train: EntitySwap\", \"Train: Noise\"],\n",
    "                linewidths=.5, cbar_kws={\"label\": \"AUROC Score\"})\n",
    "    \n",
    "    plt.title(f\"Definition-by-Negatives: Generalization Matrix (Layer {target_layer})\", fontsize=14, pad=15)\n",
    "    plt.xlabel(\"Testing Distribution\", fontsize=12)\n",
    "    plt.ylabel(\"Training Distribution\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return matrix_results\n",
    "\n",
    "# --- How to Execute ---\n",
    "# Assuming 'simpleqa_data' is your original clean SimpleQA list of dictionaries\n",
    "# (You might want to slice it e.g., simpleqa_data[:150] if you want to speed up feature extraction)\n",
    "simpleqa_data = prepare_simpleqa_data(model, tokenizer, limit=200)\n",
    "run_taxonomy_cross_validation(model, tokenizer, simpleqa_data[:150], target_layer=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
